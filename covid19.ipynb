{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":853,"status":"ok","timestamp":1631607425098,"user":{"displayName":"JAMES VUDIR MAIKASUWA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYLQhEyKBvLXDb4nRi8nF5CgIhfT_5_-UE4sJ=s64","userId":"13427145031060095908"},"user_tz":-60},"id":"skkCLWIOfGz5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","import string\n","import nltk\n","import warnings\n","%matplotlib inline \n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181842,"status":"ok","timestamp":1631607608295,"user":{"displayName":"JAMES VUDIR MAIKASUWA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYLQhEyKBvLXDb4nRi8nF5CgIhfT_5_-UE4sJ=s64","userId":"13427145031060095908"},"user_tz":-60},"id":"BkeO_h5axRge","outputId":"5e681f91-35be-4d4b-d270-737fd3d8aa57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"PZYTk8ISfvfZ"},"source":["Load datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRZWzArqfyn5"},"outputs":[],"source":["df = pd.read_csv('/content/gdrive/MyDrive/covid19.csv', encoding='utf-8')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BH2_Wx3Cxozm"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_AVpdf1etRF"},"outputs":[],"source":["#remove pattern in the dataset\n","def remove_pattern(text):\n","  text = re.findall(pattern, df)\n","  for word in text:\n","    df = re.sub(word, \"\", df)\n","  \n","  return df\n","  df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iYtt97QfM3X"},"outputs":[],"source":["#create clean function\n","def cleantxt(text):\n","  text = re.sub(r'@[A-Za-z0-9]+', '', text)\n","  text = re.sub(r'#', '', text)\n","  text = re.sub(r'RT[\\s]+', '', text)\n","  text = re.sub(r'https?:\\/\\/\\S+', '', text)\n","  text = re.sub(r'$', '', text)\n","  text = re.sub(r'\\n', '', text)\n","  text = re.sub(r'0-9[A-Za-z]+', '', text)\n","  text = text.lower()\n"," \n","\n","\n","  return text\n","  \n","df['tweets'] = df['tweets'].apply(cleantxt)\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vgVWPKnfQHG"},"outputs":[],"source":["df['clean_text'] = df['tweets'].str.replace(\"[^a-zA-Z#]\", \" \")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhxjEC5DfTBB"},"outputs":[],"source":["#remove stop words\n","df['clean_text'] = df['clean_text'].apply(lambda x: \" \".join([w for w in x.split() if len(w)\u003e3]))\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvdrwcamfW94"},"outputs":[],"source":["#tokenization\n","tokenized = df['clean_text'].apply(lambda x: x.split())\n","tokenized.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2U1tCP4ifYtH"},"outputs":[{"data":{"text/plain":["0    [preparativo, para, nuestra, patria, querida, ...\n","1    [dan, cadr, strat, vaccinal, lutt, covid, larg...\n","2    [nahuzubillahminzalik, allah, protect, from, t...\n","3    [covid, plu, ultra, gobierno, rescata, aerol, ...\n","4    [atenc, quer, taro, pasar, escenario, partir, ...\n","Name: clean_text, dtype: object"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#stemming\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","tokenized = tokenized.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n","tokenized.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YcUd_yF6ffb-"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003etweets\u003c/th\u003e\n","      \u003cth\u003eclean_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e: en los preparativos para el env√≠o a nuestra ...\u003c/td\u003e\n","      \u003ctd\u003e[preparativo, para, nuestra, patria, querida, ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003edans le cadre de la strat√©gie vaccinale de lut...\u003c/td\u003e\n","      \u003ctd\u003e[dan, cadr, strat, vaccinal, lutt, covid, larg...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e: nahuzubillahminzalik....\"may allah protect u...\u003c/td\u003e\n","      \u003ctd\u003e[nahuzubillahminzalik, allah, protect, from, t...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e: covid19 plus ultra | üî¥üí∞el gobierno rescata c...\u003c/td\u003e\n","      \u003ctd\u003e[covid, plu, ultra, gobierno, rescata, aerol, ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e_qro: atenci√≥n | quer√©taro pasar√° a escenario ...\u003c/td\u003e\n","      \u003ctd\u003e[atenc, quer, taro, pasar, escenario, partir, ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   Unnamed: 0  ...                                         clean_text\n","0           0  ...  [preparativo, para, nuestra, patria, querida, ...\n","1           1  ...  [dan, cadr, strat, vaccinal, lutt, covid, larg...\n","2           2  ...  [nahuzubillahminzalik, allah, protect, from, t...\n","3           3  ...  [covid, plu, ultra, gobierno, rescata, aerol, ...\n","4           4  ...  [atenc, quer, taro, pasar, escenario, partir, ...\n","\n","[5 rows x 3 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["df['clean_text'] = tokenized\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MeLP8EZKfnEI"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003etweets\u003c/th\u003e\n","      \u003cth\u003eclean_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e: en los preparativos para el env√≠o a nuestra ...\u003c/td\u003e\n","      \u003ctd\u003een los preparativos para el env o a nuestra ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003edans le cadre de la strat√©gie vaccinale de lut...\u003c/td\u003e\n","      \u003ctd\u003edans le cadre de la strat gie vaccinale de lut...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e: nahuzubillahminzalik....\"may allah protect u...\u003c/td\u003e\n","      \u003ctd\u003enahuzubillahminzalik     may allah protect u...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e: covid19 plus ultra | üî¥üí∞el gobierno rescata c...\u003c/td\u003e\n","      \u003ctd\u003ecovid   plus ultra     el gobierno rescata c...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e_qro: atenci√≥n | quer√©taro pasar√° a escenario ...\u003c/td\u003e\n","      \u003ctd\u003eqro  atenci n   quer taro pasar  a escenario ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   Unnamed: 0  ...                                         clean_text\n","0           0  ...    en los preparativos para el env o a nuestra ...\n","1           1  ...  dans le cadre de la strat gie vaccinale de lut...\n","2           2  ...    nahuzubillahminzalik     may allah protect u...\n","3           3  ...    covid   plus ultra     el gobierno rescata c...\n","4           4  ...   qro  atenci n   quer taro pasar  a escenario ...\n","\n","[5 rows x 3 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["df['clean_text'] = df['tweets'].str.replace(\"[^a-zA-Z#]\", \" \")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMdSUWnUfqgH"},"outputs":[],"source":["#create a function to get subjectivity\n","\n","from textblob import TextBlob\n","\n","def getsubjectivity(text):\n","  return TextBlob(text).sentiment.subjectivity\n","\n","\n","#create a function to get polarity\n","def getpolarity(text):\n","  return TextBlob(text).sentiment.polarity\n","\n","#create two new columns\n","df['subjectivity'] = df['tweets'].apply(getsubjectivity)\n","df['polarity'] = df['tweets'].apply(getpolarity)\n","\n","\n","#show new dataframe\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_k_8OoCft4k"},"outputs":[],"source":["#sentiment text function\n","def getSentiment(score):\n","    if score \u003c 0:\n","        return 'Negative'\n","    elif score ==0:\n","        return 'Neutral'\n","    else:\n","        return 'Positive'\n","    \n","#add sentiment column to dataframe\n","df['sentiment'] = df['polarity'].apply(getSentiment)\n","df[200:500]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVDcOX5kfyGJ"},"outputs":[],"source":["#Visualization and exploration of dataset\n","allWords = ' '.join( [sentence for sentence in df['clean_text']] )\n","\n","from wordcloud import WordCloud\n","wordCloud = WordCloud(width = 800, height = 500, random_state=42, max_font_size=100).generate(allWords)\n","\n","#plot wordcloud\n","plt.imshow(wordCloud, interpolation = \"bilinear\")\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVcNnxChf2Ly"},"outputs":[],"source":["#positive words visualization\n","allwords = \" \".join([sentence for sentence in df['clean_text'][df['polarity'] \u003e 0]])\n","\n","wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(allwords)\n","\n","\n","#wordcloud\n","\n","plt.imshow(wordcloud, interpolation=\"bilinear\")\n","plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cehOe_r3gJyJ"},"outputs":[],"source":["#positive words visualization\n","allwords = \" \".join([sentence for sentence in df['clean_text'][df['polarity'] \u003c 0]])\n","\n","wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(allwords)\n","\n","\n","#wordcloud\n","\n","plt.imshow(wordcloud, interpolation=\"bilinear\")\n","plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-uRYbf3gil6"},"outputs":[],"source":["#plot wordcloud \n","allWords = ' '.join( [twts for twts in df['clean_text']] )\n","wordCloud = WordCloud(width = 500, height = 300, random_state=23, max_font_size=119).generate(allWords)\n","\n","plt.imshow(wordCloud, interpolation = \"bilinear\")\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zw9RGDllgrFU"},"outputs":[],"source":["#plot polarity and subjectivity\n","plt.figure(figsize=(8,6))\n","for i in range(0, df.shape[0]):\n","  plt.scatter(df['polarity'][i], df['subjectivity'][i], color='Blue' )\n","\n","plt.title('Sentiment Analysis')\n","plt.xlabel('polarity')\n","plt.ylabel('subjectivity')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8MrO7d-lgwec"},"outputs":[],"source":["#plot and visualize counts\n","plt.title('Sentiment Analysis')\n","plt.xlabel('Sentiment')\n","plt.ylabel('Counts')\n","\n","df['sentiment'].value_counts().plot(kind='bar')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BADsYISytuv7"},"outputs":[],"source":["#creating a label for the tweets\n","def createlabel(score):\n","  if score \u003c 0:\n","    return -1\n","  elif score \u003e0 and score \u003c 1:\n","    return 1\n","  else:\n","    return 0\n","\n","\n","#add label top dataframe\n","df['label'] = df['polarity'].apply(createlabel)\n","df[200:215]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4n5DsqAlg0Uf"},"outputs":[],"source":["#input split and feature extraction\n","from sklearn.feature_extraction.text import CountVectorizer\n","bow_vect = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n","bow = bow_vect.fit_transform(df['clean_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eWYth764g56r"},"outputs":[],"source":["# bow[0].toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTuWUsw3g85G"},"outputs":[],"source":["bow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_9UgjHbhGA0"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42, test_size=0.30) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AANkagUShZ3s"},"outputs":[],"source":["print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_f7blxGchG16"},"outputs":[],"source":["#model training\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYFckiR8hH_4"},"outputs":[],"source":["# model training\n","model = LogisticRegression()\n","model.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lk5DFIBLkBy5"},"outputs":[],"source":["# testing\n","pred = model.predict(x_test)\n","accuracy_score(y_test, pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EExcTPi4hnkV"},"outputs":[],"source":["# use probabilty to get output\n","pred_prob = model.predict_proba(x_test)\n","pred = pred_prob[:,1] \u003e= 0.3\n","pred = pred.astype(np.int)\n","\n","#f1_score(y_test, pred)\n","accuracy_score(y_test, pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZErxHm4jyqu"},"outputs":[],"source":["pred_prob[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MU6cBID-1RQ6"},"outputs":[],"source":["from sklearn.naive_bayes import BernoulliNB\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","\n","BNmodel = BernoulliNB(alpha = 2)\n","SVCmodel = LinearSVC()\n","LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfkFW8ayEdM4"},"outputs":[],"source":["# model training BNB\n","model = BernoulliNB()\n","model.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkWKvSYHEdl1"},"outputs":[],"source":["# testing BNB\n","model.fit(x_test, y_test)\n","pred = model.predict(x_test)\n","accuracy_score(y_test, pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQGyfSZhEd82"},"outputs":[],"source":["# model training LSVC\n","model2 = LinearSVC()\n","model2.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2gBvPgnEeVS"},"outputs":[],"source":["# testing LSVM\n","model2.fit(x_test, y_test)\n","pred = model2.predict(x_test)\n","accuracy_score(y_test, pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krJDTUyu1c3U"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Skb9IPbv1h3f"},"outputs":[],"source":["# second split\n","train, test = train_test_split(df, test_size = 0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOYBVPso1y2h"},"outputs":[],"source":["x_train = train['clean_text']\n","x_test = test['clean_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNNo_1YQ2upq"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWGaw-VX3AuH"},"outputs":[],"source":["vector = TfidfVectorizer(use_idf=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_r7b7Bx3BWo"},"outputs":[],"source":["x_train = vector.fit_transform(x_train)\n","x_test = vector.transform(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2u-JwnD3PHY"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aV5_4_lP3aXO"},"outputs":[],"source":["def models(model):\n","  y_pred = model.predict(x_test)\n","\n","  accuracy = accuracy_score(y_pred, x_test['sentiment'])\n","  recall = recall_score(y_pred, x_test['sentiment'].pos_label='negative')\n","  precision = precision_score(y_pred, test['sentiment'].pos_label='negative')\n","\n","  return (accuracy, recall, precision)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNM9EhE0Rs1gryM5zn8aZGs","name":"covid19.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}